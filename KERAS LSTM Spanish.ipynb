{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T20:24:52.520958Z",
     "start_time": "2019-09-30T20:24:37.947938Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "        <script type=\"text/javascript\">\n",
       "        window.PlotlyConfig = {MathJaxConfig: 'local'};\n",
       "        if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}\n",
       "        if (typeof require !== 'undefined') {\n",
       "        require.undef(\"plotly\");\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': ['https://cdn.plot.ly/plotly-latest.min']\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(Plotly) {\n",
       "            window._Plotly = Plotly;\n",
       "        });\n",
       "        }\n",
       "        </script>\n",
       "        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.layers import Dropout\n",
    "import re\n",
    "#from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "#STOPWORDS = set(stopwords.words('english'))\n",
    "from bs4 import BeautifulSoup\n",
    "import plotly.graph_objs as go\n",
    "import plotly.plotly as py\n",
    "import cufflinks\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "import plotly.figure_factory as ff\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from plotly.offline import iplot\n",
    "cufflinks.go_offline()\n",
    "cufflinks.set_config_file(world_readable=True, theme='pearl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T20:24:52.545880Z",
     "start_time": "2019-09-30T20:24:52.541895Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import unicodedata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T21:29:50.196537Z",
     "start_time": "2019-09-30T21:29:50.191550Z"
    }
   },
   "outputs": [],
   "source": [
    "from imblearn.pipeline import Pipeline as make_pipeline_imb\n",
    "from imblearn.over_sampling import SMOTE,RandomOverSampler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer,CountVectorizer,TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from sklearn.metrics import balanced_accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T20:25:19.901602Z",
     "start_time": "2019-09-30T20:24:52.900577Z"
    }
   },
   "outputs": [],
   "source": [
    "df=pd.read_csv('data/train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T20:32:12.096551Z",
     "start_time": "2019-09-30T20:25:19.924504Z"
    }
   },
   "outputs": [],
   "source": [
    "temp1=df[df['label_quality']=='unreliable']['category'].tolist()\n",
    "temp2=df[df['label_quality']=='reliable']['category'].tolist()\n",
    "\n",
    "cat_not_in_reliable=list(set(temp1) - set(temp2))\n",
    "cat_count=df[(df['label_quality']=='reliable')|(df['category'].isin(cat_not_in_reliable))]['category'].value_counts()\n",
    "cat_low_count=cat_count[cat_count<4000].index.tolist()\n",
    "df=df[(df['label_quality']=='reliable')|(df['category'].isin(cat_not_in_reliable))|(df['category'].isin(cat_low_count))]\n",
    "all_cat=df['category'].value_counts()\n",
    "all_cat=all_cat[all_cat<=400].index.tolist()\n",
    "df_spanish_temp        = df[df['language']=='spanish']\n",
    "counts_spanish         = df_spanish_temp['category'].value_counts()\n",
    "low_spanish            =counts_spanish[counts_spanish<200]\n",
    "df_spanish=df[(df['language']=='spanish')|\\\n",
    "              (~df['category'].isin(counts_spanish.index))|\\\n",
    "              (df['category'].isin(all_cat))|\\\n",
    "              (df['category'].isin(low_spanish.index))]\n",
    "\n",
    "sampling_spanish={}\n",
    "counts_spanish  = df_spanish['category'].value_counts()\n",
    "for cat in counts_spanish.index:\n",
    "    if counts_spanish.loc[cat]>2200:\n",
    "        sampling_spanish[cat]=2200\n",
    "    else:\n",
    "        sampling_spanish[cat]=counts_spanish.loc[cat]\n",
    "\n",
    "X_spanish = df_spanish['title']\n",
    "y_spanish = df_spanish['category']\n",
    "\n",
    "rus_spanish = RandomUnderSampler(sampling_strategy=sampling_spanish,random_state=42)\n",
    "X_res_spanish, y_res_spanish = rus_spanish.fit_resample(X_spanish.values.reshape(-1, 1), y_spanish)\n",
    "\n",
    "#SPANISH\n",
    "X_res_spanish=pd.DataFrame(X_res_spanish)\n",
    "X_res_spanish.columns=['title']\n",
    "X_res_spanish['title']=X_res_spanish['title'].astype('str')\n",
    "y_res_spanish=pd.Series(y_res_spanish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T20:32:16.671109Z",
     "start_time": "2019-09-30T20:32:16.666144Z"
    }
   },
   "outputs": [],
   "source": [
    "def clean_text(text) :\n",
    "    text=unicodedata.normalize('NFKD', str(text)).encode('ascii', errors='ignore').decode('utf-8')\\\n",
    "    .lower().replace(r'\\\\n','').replace(r'-',' ').replace(r'.','').strip()\n",
    "    text = re.sub(\"[^a-zA-Z]\", \" \", str(text))\n",
    "    #return \" \".join(text.split())\n",
    "    return \" \".join([w for w in text.split() if len(w)>1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T20:32:39.001092Z",
     "start_time": "2019-09-30T20:32:21.224982Z"
    }
   },
   "outputs": [],
   "source": [
    "X_res_spanish['title']=X_res_spanish['title'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T21:46:54.461344Z",
     "start_time": "2019-09-30T21:46:54.196053Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POWER_GRINDERS                          2200\n",
       "PLANT_POTS_AND_PLANTERS                 2200\n",
       "PANTS                                   2200\n",
       "TRANSISTORS                             2200\n",
       "BATHROOM_VANITIES                       2200\n",
       "                                        ... \n",
       "CONSTRUCTION_LIME_BAGS                   206\n",
       "COLD_FOOD_AND_DRINK_VENDING_MACHINES     162\n",
       "PAINTBALL_SMOKE_GRENADES                 154\n",
       "COMMERCIAL_POPCORN_MACHINES              141\n",
       "HAMBURGER_FORMERS                        109\n",
       "Length: 1588, dtype: int64"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_res_spanish.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T21:49:27.980078Z",
     "start_time": "2019-09-30T21:49:27.659138Z"
    }
   },
   "outputs": [],
   "source": [
    "# RandomOverSampler\n",
    "\n",
    "sampling_ros_spanish={}\n",
    "counts_spanish  = y_res_spanish.value_counts()\n",
    "for cat in counts_spanish.index:\n",
    "    if counts_spanish.loc[cat]>1800:\n",
    "        sampling_ros_spanish[cat]=counts_spanish.loc[cat]\n",
    "    else:\n",
    "        sampling_ros_spanish[cat]=int(counts_spanish.loc[cat]+counts_spanish.loc[cat]*.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T21:51:20.978842Z",
     "start_time": "2019-09-30T21:49:32.840538Z"
    }
   },
   "outputs": [],
   "source": [
    "ros = RandomOverSampler(sampling_strategy=sampling_ros_spanish,random_state=42)\n",
    "X_ros_spanish, y_ros_spanish = ros.fit_sample(X_res_spanish.values.reshape(-1, 1), y_res_spanish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T21:51:26.114431Z",
     "start_time": "2019-09-30T21:51:25.806826Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "POWER_GRINDERS                          2200\n",
       "PLANT_POTS_AND_PLANTERS                 2200\n",
       "PANTS                                   2200\n",
       "TRANSISTORS                             2200\n",
       "BATHROOM_VANITIES                       2200\n",
       "                                        ... \n",
       "CONSTRUCTION_LIME_BAGS                   226\n",
       "COLD_FOOD_AND_DRINK_VENDING_MACHINES     178\n",
       "PAINTBALL_SMOKE_GRENADES                 169\n",
       "COMMERCIAL_POPCORN_MACHINES              155\n",
       "HAMBURGER_FORMERS                        119\n",
       "Length: 1588, dtype: int64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y_ros_spanish).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T21:51:55.861343Z",
     "start_time": "2019-09-30T21:51:55.330367Z"
    }
   },
   "outputs": [],
   "source": [
    "#SPANISH\n",
    "X_ros_spanish=pd.DataFrame(X_ros_spanish)\n",
    "X_ros_spanish.columns=['title']\n",
    "X_ros_spanish['title']=X_ros_spanish['title'].astype('str')\n",
    "y_ros_spanish=pd.Series(y_ros_spanish)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T21:52:52.671241Z",
     "start_time": "2019-09-30T21:52:15.991847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 295737 unique tokens.\n"
     ]
    }
   ],
   "source": [
    "# The maximum number of words to be used. (most frequent)\n",
    "MAX_NB_WORDS = 50000\n",
    "# Max number of words in each title.\n",
    "MAX_SEQUENCE_LENGTH = 40\n",
    "# This is fixed.\n",
    "EMBEDDING_DIM = 100\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_NB_WORDS, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(X_ros_spanish['title'].values)\n",
    "word_index = tokenizer.word_index\n",
    "print('Found %s unique tokens.' % len(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T21:53:40.448270Z",
     "start_time": "2019-09-30T21:52:57.778755Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of data tensor: (2996106, 40)\n"
     ]
    }
   ],
   "source": [
    "X = tokenizer.texts_to_sequences(X_ros_spanish['title'].values)\n",
    "X = pad_sequences(X, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "print('Shape of data tensor:', X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T21:54:01.207778Z",
     "start_time": "2019-09-30T21:53:56.914767Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of label tensor: (2996106, 1588)\n"
     ]
    }
   ],
   "source": [
    "y = pd.get_dummies(y_ros_spanish).values\n",
    "print('Shape of label tensor:', y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T21:55:31.897325Z",
     "start_time": "2019-09-30T21:55:26.359949Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1498053, 40) (1498053, 1588)\n",
      "(1498053, 40) (1498053, 1588)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.5, random_state = 42,)# stratify=y)\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T21:55:37.391687Z",
     "start_time": "2019-09-30T21:55:36.927846Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 40, 100)           5000000   \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 40, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               80400     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1588)              160388    \n",
      "=================================================================\n",
      "Total params: 5,240,788\n",
      "Trainable params: 5,240,788\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(MAX_NB_WORDS, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1588, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['categorical_accuracy']) # accuracy\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T02:16:29.146187Z",
     "start_time": "2019-09-30T22:03:31.750987Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\envs\\keras\\lib\\site-packages\\tensorflow_core\\python\\framework\\indexed_slices.py:424: UserWarning:\n",
      "\n",
      "Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1348247 samples, validate on 149806 samples\n",
      "Epoch 1/7\n",
      "1348247/1348247 [==============================] - 2235s 2ms/step - loss: 2.1247 - categorical_accuracy: 0.6347 - val_loss: 0.9516 - val_categorical_accuracy: 0.8184\n",
      "Epoch 2/7\n",
      "1348247/1348247 [==============================] - 2252s 2ms/step - loss: 0.9435 - categorical_accuracy: 0.8151 - val_loss: 0.8420 - val_categorical_accuracy: 0.8366\n",
      "Epoch 3/7\n",
      "1348247/1348247 [==============================] - 2136s 2ms/step - loss: 0.8219 - categorical_accuracy: 0.8337 - val_loss: 0.8108 - val_categorical_accuracy: 0.8435\n",
      "Epoch 4/7\n",
      "1348247/1348247 [==============================] - 2142s 2ms/step - loss: 0.7625 - categorical_accuracy: 0.8428 - val_loss: 0.7966 - val_categorical_accuracy: 0.8464\n",
      "Epoch 5/7\n",
      "1348247/1348247 [==============================] - 2140s 2ms/step - loss: 0.7243 - categorical_accuracy: 0.8489 - val_loss: 0.7870 - val_categorical_accuracy: 0.8482\n",
      "Epoch 6/7\n",
      "1348247/1348247 [==============================] - 2135s 2ms/step - loss: 0.6971 - categorical_accuracy: 0.8528 - val_loss: 0.7870 - val_categorical_accuracy: 0.8489\n",
      "Epoch 7/7\n",
      "1348247/1348247 [==============================] - 2137s 2ms/step - loss: 0.6770 - categorical_accuracy: 0.8560 - val_loss: 0.7841 - val_categorical_accuracy: 0.8504\n"
     ]
    }
   ],
   "source": [
    "epochs = 7\n",
    "batch_size = 64\n",
    "history = model.fit(X_train, y_train,\n",
    "                    epochs=epochs, batch_size=batch_size,\n",
    "                    validation_split=0.1,\n",
    "                    callbacks=[EarlyStopping(monitor='val_loss', patience=3, min_delta=0.0001)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T12:37:37.117507Z",
     "start_time": "2019-10-01T12:32:33.481707Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1498053/1498053 [==============================] - 304s 203us/step\n",
      "Test set\n",
      "  Loss: 0.788\n",
      "  Accuracy: 0.849\n"
     ]
    }
   ],
   "source": [
    "accr = model.evaluate(X_test,y_test)\n",
    "print('Test set\\n  Loss: {:0.3f}\\n  Accuracy: {:0.3f}'.format(accr[0],accr[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.846"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T12:37:46.065759Z",
     "start_time": "2019-10-01T12:37:41.739332Z"
    }
   },
   "outputs": [],
   "source": [
    "labels = pd.get_dummies(y_res_spanish).columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-09-30T19:26:45.330199Z",
     "start_time": "2019-09-30T19:26:45.314264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEA\n"
     ]
    }
   ],
   "source": [
    "title = 'Te Rojo En Hebras   X 1 Kg Nacional Imperdible'\n",
    "title_clean = clean_text(title)\n",
    "seq = tokenizer.texts_to_sequences([title_clean])\n",
    "padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "pred = model.predict(padded)\n",
    "print(labels[np.argmax(pred)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T12:37:51.620691Z",
     "start_time": "2019-10-01T12:37:50.717345Z"
    }
   },
   "outputs": [],
   "source": [
    "model.save('models/LSTM_spanish.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T12:37:56.970402Z",
     "start_time": "2019-10-01T12:37:56.321140Z"
    }
   },
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T12:38:02.517855Z",
     "start_time": "2019-10-01T12:38:01.753614Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pred_spanish=df_test[df_test['language']=='spanish']\n",
    "df_pred_spanish['title']=df_pred_spanish['title'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T12:38:07.137945Z",
     "start_time": "2019-10-01T12:38:07.132932Z"
    }
   },
   "outputs": [],
   "source": [
    "def prediction(title):\n",
    "    seq = tokenizer.texts_to_sequences([title])\n",
    "    padded = pad_sequences(seq, maxlen=MAX_SEQUENCE_LENGTH)\n",
    "    pred = model.predict(padded)\n",
    "    return labels[np.argmax(pred)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T12:42:40.631545Z",
     "start_time": "2019-10-01T12:38:11.773014Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pred_spanish['category'] = df_pred_spanish['title'].apply(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T12:42:45.349345Z",
     "start_time": "2019-10-01T12:42:45.331359Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>language</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>disco rigido externo western digital elements ...</td>\n",
       "      <td>spanish</td>\n",
       "      <td>HARD_DRIVES_AND_SSDS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>picadora de carne fineschi legitima</td>\n",
       "      <td>spanish</td>\n",
       "      <td>MEAT_GRINDERS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>set barreta automotor bremen unid cm</td>\n",
       "      <td>spanish</td>\n",
       "      <td>CROWBARS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>miel organica gr sin tacc</td>\n",
       "      <td>spanish</td>\n",
       "      <td>HONEY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>bandeja giradiscos omnitronic bd</td>\n",
       "      <td>spanish</td>\n",
       "      <td>TURNTABLES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id                                              title language  \\\n",
       "9    9  disco rigido externo western digital elements ...  spanish   \n",
       "10  10                picadora de carne fineschi legitima  spanish   \n",
       "14  14               set barreta automotor bremen unid cm  spanish   \n",
       "15  15                          miel organica gr sin tacc  spanish   \n",
       "19  19                   bandeja giradiscos omnitronic bd  spanish   \n",
       "\n",
       "                category  \n",
       "9   HARD_DRIVES_AND_SSDS  \n",
       "10         MEAT_GRINDERS  \n",
       "14              CROWBARS  \n",
       "15                 HONEY  \n",
       "19            TURNTABLES  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pred_spanish.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-01T12:42:50.391072Z",
     "start_time": "2019-10-01T12:42:50.017823Z"
    }
   },
   "outputs": [],
   "source": [
    "df_pred_spanish.to_csv('submit/submit_lstm_spanish.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
